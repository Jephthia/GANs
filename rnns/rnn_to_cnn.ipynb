{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, Reshape, LeakyReLU, Conv2DTranspose\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.io.gfile import GFile\n",
    "from tensorflow.strings import unicode_split\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager():    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.ids_to_chars_layer = None\n",
    "    \n",
    "    def decode_text(self, ids):\n",
    "        if self.ids_to_chars_layer is None:\n",
    "            return None\n",
    "\n",
    "        return tf.strings.reduce_join(self.ids_to_chars_layer(ids), axis=-1)\n",
    "    \n",
    "    def parse_img(self, file_name):\n",
    "        img = tf.io.read_file(file_name)\n",
    "        img = tf.io.decode_png(img, channels=3)\n",
    "        img = tf.image.resize(img, [224, 224], antialias=True, method='nearest')\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def get_img_ds(self):\n",
    "        file_names = glob.glob('datasets/imgs/*')\n",
    "        img_ds = Dataset.from_tensor_slices(file_names)\n",
    "        img_ds = img_ds.map(self.parse_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        img_ds = img_ds.batch(C.BATCH_SIZE)\n",
    "        \n",
    "        return img_ds\n",
    "    \n",
    "\n",
    "    def get_svg_ds(self):\n",
    "        data = GFile('datasets/svgs/simpleline.svg', 'rb').read().decode(encoding='UTF-8')\n",
    "        \n",
    "        # Get the list of the unique characters in the text\n",
    "        vocab = ['e', 'g', 'n', 'r', '\\n']\n",
    "        vocab_size = len(vocab)\n",
    "        \n",
    "        # Build the id to char lookup table\n",
    "        chars_to_ids = StringLookup(vocabulary=vocab)\n",
    "        self.ids_to_chars_layer = StringLookup(vocabulary=chars_to_ids.get_vocabulary(), invert=True)\n",
    "\n",
    "        # Split the entire text by character\n",
    "        chars = unicode_split(data, 'UTF-8')\n",
    "        ids_of_chars = chars_to_ids(chars)\n",
    "        \n",
    "        # Group characters to form sequences\n",
    "        svg_ds = Dataset.from_tensor_slices(ids_of_chars)\n",
    "        svg_ds = svg_ds.batch(C.SEQUENCE_LENGTH)\n",
    "        svg_ds = svg_ds.batch(C.BATCH_SIZE)\n",
    "        \n",
    "        return svg_ds\n",
    "\n",
    "    def load_data(self):\n",
    "        img_ds = self.get_img_ds()\n",
    "        svg_ds = self.get_svg_ds()\n",
    "\n",
    "        # Batch the sequences\n",
    "        ds = Dataset.zip((svg_ds, img_ds))\n",
    "        ds = ds.shuffle(C.BUFFER_SIZE)\n",
    "        ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    def to_inputs_and_targets(self, sequences):\n",
    "        # Exclude the last character\n",
    "        inputs = sequences[:, :-1] # H e l l o -> H e l l\n",
    "        # Exclude the first character\n",
    "        targets = sequences[:, 1:] # H e l l o -> e l l o\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainManager():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.dataset = None\n",
    "        self.data_manager = DataManager(C.DATA_PATH)\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.dataset = self.data_manager.load_data()\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(input_dim=C.VOCAB_SIZE, output_dim=C.EMBEDDING_DIM))\n",
    "        self.model.add(SimpleRNN(128))\n",
    "        \n",
    "        # 7x7\n",
    "        self.model.add(Dense(128 * 7 * 7))\n",
    "        self.model.add(LeakyReLU(alpha=0.02))\n",
    "        self.model.add(Reshape((7, 7, 128)))\n",
    "        # 14x14\n",
    "        self.model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        self.model.add(LeakyReLU(alpha=0.02))\n",
    "        # 28x28\n",
    "        self.model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        self.model.add(LeakyReLU(alpha=0.02))\n",
    "        # 56x56\n",
    "        self.model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        self.model.add(LeakyReLU(alpha=0.02))\n",
    "        # 112x112\n",
    "        self.model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        self.model.add(LeakyReLU(alpha=0.02))\n",
    "        # 224x224\n",
    "        self.model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        self.model.add(LeakyReLU(alpha=0.02))\n",
    "        # Final image\n",
    "        self.model.add(tf.keras.layers.Conv2D(3, (7, 7), activation='sigmoid', padding='same'))\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(lr=C.INITIAL_LR),\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        )\n",
    "        \n",
    "    def sample_text(self):\n",
    "        preds = self.model.predict(self.dataset)\n",
    "\n",
    "        print('preds shape', preds.shape)\n",
    "\n",
    "        sampled_indices = tf.random.categorical(preds[0], num_samples=1)\n",
    "        sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "        pred_text = self.data_manager.decode_text(sampled_indices)\n",
    "\n",
    "        print('pred', pred_text.numpy())\n",
    "        \n",
    "    def train(self):\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "            \n",
    "        if self.dataset is None:\n",
    "            self.load_data()\n",
    "            \n",
    "        self.model.fit(self.dataset, epochs=C.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.2500\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2191\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0396\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0066\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0066\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0066\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0066\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0066\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0066\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0066\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0066\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0066\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0066\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0066\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0066\n"
     ]
    }
   ],
   "source": [
    "class C:\n",
    "    # --- DATA --- #\n",
    "    SEQUENCE_LENGTH = 100\n",
    "    BATCH_SIZE = 8\n",
    "    VOCAB_SIZE = 67\n",
    "    EMBEDDING_DIM = 56\n",
    "    BUFFER_SIZE = 10000\n",
    "    DATA_PATH = 'datasets/simpleline.svg'\n",
    "    \n",
    "    # -- TRAINING -- #\n",
    "    EPOCHS = 50\n",
    "    INITIAL_LR = 1e-02\n",
    "\n",
    "tm = TrainManager()\n",
    "\n",
    "# tm.load_model()\n",
    "tm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd6453bf160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOJElEQVR4nO3df+hd9X3H8edr/oKpUF2rhJguUdIyLSO2YgdO6X60WhmNDuwio4RNFgsKLXSwqLDJ/uq62v4zaklRlo3OH5u1BulWQyj1n1WNbRqNaWqiqX5NSFY7pttKu6Tv/XHPl16Tb8zXe+/x3i+f5wO+3HM/55zveR8OeeXcc7983qkqJLXrV6ZdgKTpMgSkxhkCUuMMAalxhoDUOENAalxvIZDkmiR7kuxNsrGv40gaT/r4O4EkpwA/BD4MzAFPATdW1XMTP5iksfR1J3A5sLeqXqiqnwP3A2t7OpakMZza0+9dDrw89H4O+OCJNk7iny1K/ftxVb3r2MG+QiALjL3hH3qSDcCGno4v6Xg/WmiwrxCYA1YMvb8AODC8QVVtAjaBdwLSNPX1TOApYHWSVUlOB9YBW3o6lqQx9HInUFVHktwKfBM4Bbi3qnb1cSxJ4+nlK8K3XIQfB6S3w9NVddmxg/7FoNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjRg6BJCuSfCvJ7iS7knyqG78zyStJdnQ/106uXEmTNs7MQkeAz1TVd5OcDTydZGu37otV9fnxy5PUt5FDoKoOAge75deT7GYw1bikJWQizwSSrAQuBZ7ohm5NsjPJvUnOmcQxJPVj7BBIchbwEPDpqnoNuBu4CFjD4E7hrhPstyHJ9iTbx61B0ujGmmg0yWnAo8A3q+oLC6xfCTxaVe87ye9xolGpf5OdaDRJgHuA3cMBkGTZ0GbXA8+OegxJ/Rvn24ErgE8AzyTZ0Y3dDtyYZA2DtmP7gZvHOIakntl3QGqHfQckHc8QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGrcODMLkWQ/8DpwFDhSVZclORd4AFjJYGahj1fVf45XpqS+TOJO4Heqas3QjCUbgW1VtRrY1r2XNKP6+DiwFtjcLW8GruvhGJImZNwQKOCxJE8n2dCNnd91J5rvUnTeQjvad0CaDWM9EwCuqKoDSc4Dtib5wWJ3rKpNwCZwolFpmsa6E6iqA93rYeBh4HLg0Hzvge718LhFSurPOM1Hzuy6EZPkTOAjDBqNbAHWd5utBx4Zt0hJ/Rnn48D5wMODRkScCvxTVf1bkqeAB5PcBLwE3DB+mZL6YvMRqR02H5F0PENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGGQJS40aeVCTJexn0F5h3IfCXwDuAPwP+oxu/vaq+MepxJPVrIpOKJDkFeAX4IPAnwH9X1effwv5OKiL1r9dJRX4P2FdVP5rQ75P0NplUCKwD7ht6f2uSnUnuTXLOhI4hqQdjh0CS04GPAf/cDd0NXASsAQ4Cd51gP5uPSDNg7GcCSdYCt1TVRxZYtxJ4tKred5Lf4TMBqX+9PRO4kaGPAvONRzrXM+hFIGlGjdua/FeBDwM3Dw1/LskaBn0K9x+zTtKMse+A1A77Dkg6niEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcScNgW6y0MNJnh0aOzfJ1iTPd6/nDK27LcneJHuSXN1X4ZImYzF3An8PXHPM2EZgW1WtBrZ170lyMYOZhy/p9vlS15NA0ow6aQhU1ePAT44ZXgts7pY3A9cNjd9fVT+rqheBvcDlkylVUh9GfSZwflUdBOhez+vGlwMvD203141JmlFjTTS6gCwwtuD8gUk2ABsmfHxJb9GodwKH5qcW714Pd+NzwIqh7S4ADiz0C6pqU1VdttDEh5LePqOGwBZgfbe8HnhkaHxdkjOSrAJWA0+OV6KkPp3040CS+4APAe9MMgf8FfBZ4MEkNwEvATcAVNWuJA8CzwFHGHQmOtpT7ZImwL4DUjvsOyDpeIaA1DhDQGqcISA1zhCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuNGbT7yt0l+kGRnkoeTvKMbX5nkp0l2dD9f7rF2SRMwavORrcD7quo3gR8Ctw2t21dVa7qfT06mTEl9Gan5SFU9VlVHurffYTCrsKQlaBLPBP4U+Neh96uSfC/Jt5NceaKdkmxIsj3J9gnUIGlEYzUfSXIHg1mFv9oNHQTeXVWvJvkA8PUkl1TVa8fuW1WbgE3d73GiUWlKRr4TSLIe+APgj6ubsrjrQfhqt/w0sA94zyQKldSPkUIgyTXAXwAfq6r/HRp/13wX4iQXMmg+8sIkCpXUj1Gbj9wGnAFsTQLwne6bgKuAv05yBDgKfLKqju1oLGmG2HxEaofNRyQdzxCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUuFH7DtyZ5JWh/gLXDq27LcneJHuSXN1X4ZImY9S+AwBfHOov8A2AJBcD64BLun2+ND/dmKTZNFLfgTexFri/m3D0RWAvcPkY9Unq2TjPBG7t2pDdm+Scbmw58PLQNnPd2HHsOyDNhlFD4G7gImANg14Dd3XjWWDbBecPrKpNVXXZQnOeSXr7jBQCVXWoqo5W1S+Ar/DLW/45YMXQphcAB8YrUVKfRu07sGzo7fXA/DcHW4B1Sc5IsopB34EnxytRUp9G7TvwoSRrGNzq7wduBqiqXUkeBJ5j0J7slqo62kvlkibCvgNSO+w7IOl4hoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGjdp34IGhngP7k+zoxlcm+enQui/3WLukCTjpzEIM+g78HfAP8wNV9Ufzy0nuAv5raPt9VbVmQvVJ6tlJQ6CqHk+ycqF1SQJ8HPjdCdcl6W0y7jOBK4FDVfX80NiqJN9L8u0kV475+yX1bDEfB97MjcB9Q+8PAu+uqleTfAD4epJLquq1Y3dMsgHYMObxJY1p5DuBJKcCfwg8MD/WtR97tVt+GtgHvGeh/W0+Is2GcT4O/D7wg6qamx9I8q75BqRJLmTQd+CF8UqU1KfFfEV4H/DvwHuTzCW5qVu1jjd+FAC4CtiZ5PvAvwCfrKrFNjOVNAX2HZDaYd8BScczBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDVuMZOKrEjyrSS7k+xK8qlu/NwkW5M8372eM7TPbUn2JtmT5Oo+T0DSeBZzJ3AE+ExV/QbwW8AtSS4GNgLbqmo1sK17T7duHXAJcA3wpfkpxyTNnpOGQFUdrKrvdsuvA7uB5cBaYHO32Wbgum55LXB/N+noi8Be4PIJ1y1pQt7SM4GuCcmlwBPA+VV1EAZBAZzXbbYceHlot7luTNIMWnTfgSRnAQ8Bn66q1wbNhxbedIGx4+YQtO+ANBsWdSeQ5DQGAfDVqvpaN3woybJu/TLgcDc+B6wY2v0C4MCxv9O+A9JsWMy3AwHuAXZX1ReGVm0B1nfL64FHhsbXJTkjySoGvQeenFzJkiZpMR8HrgA+ATwz34IcuB34LPBg14fgJeAGgKraleRB4DkG3yzcUlVHJ124pMmw74DUDvsOSDqeISA1zhCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDVu0VOO9+zHwP90r0vVO1na9cPSP4elXj/0ew6/vtDgTMwxCJBk+1Kefnyp1w9L/xyWev0wnXPw44DUOENAatwshcCmaRcwpqVePyz9c1jq9cMUzmFmnglImo5ZuhOQNAVTD4Ek1yTZk2Rvko3TrmexkuxP8kySHUm2d2PnJtma5Pnu9Zxp1zkvyb1JDid5dmjshPUmua27JnuSXD2dqt/oBOdwZ5JXuuuwI8m1Q+tm6hySrEjyrSS7k+xK8qlufLrXoaqm9gOcAuwDLgROB74PXDzNmt5C7fuBdx4z9jlgY7e8Efibadc5VNtVwPuBZ09WL3Bxdy3OAFZ11+iUGT2HO4E/X2DbmTsHYBnw/m75bOCHXZ1TvQ7TvhO4HNhbVS9U1c+B+4G1U65pHGuBzd3yZuC66ZXyRlX1OPCTY4ZPVO9a4P6q+llVvQjsZXCtpuoE53AiM3cOVXWwqr7bLb8O7AaWM+XrMO0QWA68PPR+rhtbCgp4LMnTSTZ0Y+dX1UEYXHDgvKlVtzgnqnepXZdbk+zsPi7M30rP9DkkWQlcCjzBlK/DtEMgC4wtla8rrqiq9wMfBW5JctW0C5qgpXRd7gYuAtYAB4G7uvGZPYckZwEPAZ+uqtfebNMFxiZ+DtMOgTlgxdD7C4ADU6rlLamqA93rYeBhBrdph5IsA+heD0+vwkU5Ub1L5rpU1aGqOlpVvwC+wi9vl2fyHJKcxiAAvlpVX+uGp3odph0CTwGrk6xKcjqwDtgy5ZpOKsmZSc6eXwY+AjzLoPb13WbrgUemU+GinajeLcC6JGckWQWsBp6cQn0nNf+Pp3M9g+sAM3gOSQLcA+yuqi8MrZrudZiBJ77XMnhKug+4Y9r1LLLmCxk8tf0+sGu+buDXgG3A893rudOudajm+xjcLv8fg/9hbnqzeoE7umuyB/jotOt/k3P4R+AZYGf3j2bZrJ4D8NsMbud3Aju6n2unfR38i0GpcdP+OCBpygwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxv0/k8UEbv4J7jQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = tm.model.predict(next(iter(tm.dataset))[0])\n",
    "\n",
    "plt.imshow(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 100, 56)           3752      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 128)               23680     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6272)              809088    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 28, 28, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 56, 56, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 112, 112, 128)     262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 224, 224, 128)     262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 224, 224, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 224, 224, 3)       18819     \n",
      "=================================================================\n",
      "Total params: 2,166,699\n",
      "Trainable params: 2,166,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tm.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[3, 5, 2, 2, 4, 6]])>,\n",
       " <tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
       " array([[[[0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tttt = DataManager('dsa')\n",
    "myds = tttt.load_data()\n",
    "\n",
    "next(iter(myds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
